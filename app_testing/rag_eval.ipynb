{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Setting up the vector database...\n",
      "✅ Vector database initialized\n",
      "\n",
      "Step 2: Loading profiles from CSV...\n",
      "✅ Loaded 20 profiles from CSV\n",
      "\n",
      "Step 3: Creating LangChain documents for embedding...\n",
      "\n",
      "Sample document for embedding:\n",
      "--------------------------------------------------\n",
      "Document ID (UUID4): 76749484-3c7f-42cc-b615-623e55fb205c\n",
      "Name: Keith Teare\n",
      "Location: Palo Alto, California, United States, United States\n",
      "About: I am a founder and CEO at SignalRank, a technology company that uses data intelligence to form a partner network with top-performing managers. We have built a financial instrument that captures top decile value creation that is exclusive to the best early stage companies. I have over 40 years of experience in digital technology, as a founder, CTO, or CEO, in various domains, such as internet services, keywords...\n",
      "--------------------------------------------------\n",
      "✅ Created 20 documents with UUID4 identifiers\n",
      "\n",
      "Step 4: Creating LangChain vector store and retriever...\n",
      "Processing batch 1/2 (documents 1-10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_420251/3960717125.py:28: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n",
      "/tmp/ipykernel_420251/3960717125.py:122: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
      "  vector_store = Qdrant(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting 1 second before next batch...\n",
      "Processing batch 2/2 (documents 11-20)...\n",
      "✅ Finished processing 20 documents with UUID4 identifiers\n",
      "✅ Created LangChain retriever\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.schema.document import Document\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import uuid  # Import UUID module\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "COLLECTION_NAME = \"founders\"\n",
    "VECTOR_DIM = 1536  # OpenAI embedding dimension\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "BATCH_SIZE = 10  # Process profiles in smaller batches to avoid rate limits\n",
    "\n",
    "print(\"Step 1: Setting up the vector database...\")\n",
    "# Initialize Qdrant client (in-memory)\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create collection\n",
    "client.recreate_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(size=VECTOR_DIM, distance=Distance.COSINE)\n",
    ")\n",
    "print(\"✅ Vector database initialized\")\n",
    "\n",
    "print(\"\\nStep 2: Loading profiles from CSV...\")\n",
    "# Update this path to your CSV file location\n",
    "csv_path = \"specter-people-db--export_small.csv\"  # Update this to your CSV file path\n",
    "df = pd.read_csv(csv_path)\n",
    "profiles = df.to_dict('records')\n",
    "print(f\"✅ Loaded {len(profiles)} profiles from CSV\")\n",
    "\n",
    "print(\"\\nStep 3: Creating LangChain documents for embedding...\")\n",
    "# Initialize the embeddings model\n",
    "embeddings_model = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "\n",
    "# Create LangChain documents with UUID4 IDs\n",
    "documents = []\n",
    "document_ids = []  # Store UUIDs separately\n",
    "\n",
    "for p in profiles:\n",
    "    # Generate a UUID4 for this document\n",
    "    doc_id = str(uuid.uuid4())\n",
    "    \n",
    "    # Build a text representation including key fields\n",
    "    text_parts = []\n",
    "    \n",
    "    # Add core identity information\n",
    "    if p.get('Full Name'): text_parts.append(f\"Name: {p.get('Full Name')}\")\n",
    "    if p.get('Current Position'): text_parts.append(f\"Position: {p.get('Current Position Title')}\")\n",
    "    if p.get('Company'): text_parts.append(f\"Company: {p.get('Current Position Company Name')}\")\n",
    "    if p.get('Location'): text_parts.append(f\"Location: {p.get('Location')}\")\n",
    "    \n",
    "    # Add contact and social media information\n",
    "    if p.get('LinkedIn'): text_parts.append(f\"LinkedIn: {p.get('LinkedIn - URL')}\")\n",
    "    if p.get('Twitter'): text_parts.append(f\"Twitter: {p.get('Twitter - URL')}\")\n",
    "    if p.get('Website'): text_parts.append(f\"Website: {p.get('Website - URL')}\")\n",
    "    if p.get('Email'): text_parts.append(f\"Email: {p.get('Email')}\")\n",
    "    \n",
    "    # Add detailed professional information\n",
    "    if p.get('About'): text_parts.append(f\"About: {p.get('About')}\")\n",
    "    if p.get('Skills'): text_parts.append(f\"Skills: {p.get('Skills')}\")\n",
    "    if p.get('Experience'): text_parts.append(f\"Experience: {p.get('Experience')}\")\n",
    "    if p.get('Education'): text_parts.append(f\"Education: {p.get('Education')}\")\n",
    "    \n",
    "    # Add any industry or sector information\n",
    "    if p.get('Industry'): text_parts.append(f\"Industry: {p.get('Industry')}\")\n",
    "    if p.get('Sector'): text_parts.append(f\"Sector: {p.get('Sector')}\")\n",
    "    \n",
    "    # Add any entrepreneurial information\n",
    "    if p.get('Previous Startups'): text_parts.append(f\"Previous Startups: {p.get('Previous Startups')}\")\n",
    "    if p.get('Funding History'): text_parts.append(f\"Funding History: {p.get('Funding History')}\")\n",
    "    \n",
    "    # Add any additional fields that might be in the CSV\n",
    "    for key, value in p.items():\n",
    "        if (key not in ['Full Name', 'Current Position', 'Company', 'Location', \n",
    "                       'LinkedIn', 'Twitter', 'Website', 'Email',\n",
    "                       'About', 'Skills', 'Experience', 'Education', \n",
    "                       'Industry', 'Sector', 'Previous Startups', 'Funding History'] \n",
    "            and value and str(value).lower() != 'nan'):\n",
    "            text_parts.append(f\"{key}: {value}\")\n",
    "    \n",
    "    # Join all parts with newlines for better separation\n",
    "    text = \"\\n\".join(text_parts)\n",
    "    \n",
    "    # Add the UUID to the metadata\n",
    "    p['doc_id'] = doc_id\n",
    "    \n",
    "    # Create a LangChain Document with the text and metadata\n",
    "    document = Document(\n",
    "        page_content=text,\n",
    "        metadata=p  # Store the original profile as metadata (now includes doc_id)\n",
    "    )\n",
    "    documents.append(document)\n",
    "    document_ids.append(doc_id)\n",
    "\n",
    "# Print a sample document with its UUID\n",
    "if documents:\n",
    "    print(\"\\nSample document for embedding:\")\n",
    "    print(\"-\" * 50)\n",
    "    sample_doc = documents[0]\n",
    "    sample_id = document_ids[0]\n",
    "    print(f\"Document ID (UUID4): {sample_id}\")\n",
    "    if len(sample_doc.page_content) > 500:\n",
    "        print(sample_doc.page_content[:500] + \"...\")\n",
    "    else:\n",
    "        print(sample_doc.page_content)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(f\"✅ Created {len(documents)} documents with UUID4 identifiers\")\n",
    "\n",
    "print(\"\\nStep 4: Creating LangChain vector store and retriever...\")\n",
    "# First, create the vector store with the existing client\n",
    "vector_store = Qdrant(\n",
    "    client=client,  # Use the existing client\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embeddings=embeddings_model\n",
    ")\n",
    "\n",
    "# Process in batches to avoid rate limits\n",
    "total_documents = len(documents)\n",
    "num_batches = (total_documents + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "# Process documents in batches\n",
    "for batch_idx in range(num_batches):\n",
    "    start_idx = batch_idx * BATCH_SIZE\n",
    "    end_idx = min(start_idx + BATCH_SIZE, total_documents)\n",
    "    \n",
    "    print(f\"Processing batch {batch_idx+1}/{num_batches} (documents {start_idx+1}-{end_idx})...\")\n",
    "    \n",
    "    batch_docs = documents[start_idx:end_idx]\n",
    "    batch_ids = document_ids[start_idx:end_idx]\n",
    "    \n",
    "    try:\n",
    "        # Extract texts and metadatas from documents\n",
    "        texts = [doc.page_content for doc in batch_docs]\n",
    "        metadatas = [doc.metadata for doc in batch_docs]\n",
    "        \n",
    "        # Add texts to the vector store with their UUIDs\n",
    "        vector_store.add_texts(\n",
    "            texts=texts,\n",
    "            metadatas=metadatas,\n",
    "            ids=batch_ids  # Use UUID4 strings as IDs\n",
    "        )\n",
    "        \n",
    "        # Sleep to avoid rate limits\n",
    "        if batch_idx < num_batches - 1:\n",
    "            print(\"Waiting 1 second before next batch...\")\n",
    "            time.sleep(1)  # 1 second delay between batches\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {batch_idx+1}/{num_batches}: {str(e)}\")\n",
    "        # Continue with next batch\n",
    "\n",
    "print(f\"✅ Finished processing {total_documents} documents with UUID4 identifiers\")\n",
    "\n",
    "# Create a retriever from the vector store\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",  # Options: \"similarity\", \"mmr\"\n",
    "    search_kwargs={\"k\": 3}     # Return top 3 results\n",
    ")\n",
    "\n",
    "print(\"✅ Created LangChain retriever\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE 1: BASIC RETRIEVAL\n",
      "==================================================\n",
      "Retrieving documents for: 'AI experts in healthcare'\n",
      "Retrieved 3 documents\n",
      "\n",
      "Result #1: Alexey Skutin\n",
      "Document ID: ef776d21-76d3-4fd2-b9b2-36428f019e0f\n",
      "Position: N/A\n",
      "Company: N/A\n",
      "Location: Pacifica, California, United States, United States\n",
      "Skills: [\"Cloud Computing\",\"Software Development\",\"Product Management\",\"Start-ups\",\"SaaS\",\"Agile Methodologies\",\"Entrepreneurship\",\"Enterprise Software\",\"Java\",\"Mobile Applications\",\"PaaS\",\"Project Management\",\"Software Project Management\",\"Business Intelligence\",\"IaaS\",\"Java Enterprise Edition\",\"Web Development\",\"Apache\",\"Integration\",\"MySQL\",\"Scrum\",\"Cloud Security\",\"Distributed Systems\",\"Leadership\",\"Management skills\",\"Mobile Devices\",\"Scalability\",\"Software Engineering\",\"Software as a Service (SaaS)\",\"Technical expertise\",\"Web Services\",\"Git\",\"PHP\",\"Strategic Partnerships\",\"Web Applications\",\"Analytical Skills\",\"B2B2C\",\"B2C\",\"Business-to-Business (B2B)\",\"Cost Management\",\"ERP Software\",\"Problem Solving\",\"Risk Management\",\"SQL\",\"System Architecture\",\"Virtual Private Network (VPN)\"]\n",
      "Content snippet: Name: Alexey Skutin\n",
      "Location: Pacifica, California, United States, United States\n",
      "About: Hi! I'm Alexey, a Ph.D.-educated IT leader with 20+ years of experience in the IT industry, specializing in ente...\n",
      "\n",
      "Result #2: Anthony Kelani\n",
      "Document ID: 64be26e6-5499-442a-a783-c5e9dd74a033\n",
      "Position: N/A\n",
      "Company: N/A\n",
      "Location: Los Angeles, California, United States, United States\n",
      "Skills: [\"JavaScript\",\"Android\",\"C++\",\"Software Development\",\"Java\",\"Web Development\",\"CSS\",\"Mobile Applications\",\"JSON\",\"Start-ups\",\"Ruby on Rails\",\"OS X\",\"Software Project Management\",\"iOS\",\"Android Development\",\"HTML\",\"Objective-C\",\"Software Engineering\",\"Ubuntu\",\"Adobe Creative Suite\",\"C\",\"Mobile Devices\",\"Project Management\",\"Xcode\",\"AngularJS\",\"Artificial Intelligence (AI)\",\"Avatars\",\"Cryptocurrency\",\"Deep Learning\",\"DevOps\",\"H.264\",\"Large Language Models (LLM)\",\"Mac OS X\",\"OpenAI\",\"Real Time System Design\",\"SIP\",\"VoIP\",\"Web Application Development\",\"Webrtc\"]\n",
      "Content snippet: Name: Anthony Kelani\n",
      "Location: Los Angeles, California, United States, United States\n",
      "About: With over 20 years of experience in the tech industry, I am passionate about creating innovative solutions t...\n",
      "\n",
      "Result #3: Christopher Obereder\n",
      "Document ID: 6dc877bb-1323-460c-897b-1446e4ea6dcf\n",
      "Position: N/A\n",
      "Company: N/A\n",
      "Location: Atherton, California, United States, United States\n",
      "Skills: nan\n",
      "Content snippet: Name: Christopher Obereder\n",
      "Location: Atherton, California, United States, United States\n",
      "About: With a rich tapestry of experience spanning over 12 years in the tech realm, I stand as a seasoned entrep...\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"EXAMPLE 1: BASIC RETRIEVAL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "query = \"AI experts in healthcare\"  # You can change this query\n",
    "print(f\"Retrieving documents for: '{query}'\")\n",
    "\n",
    "# Retrieve documents\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "# Display results\n",
    "print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    profile = doc.metadata\n",
    "    \n",
    "    print(f\"\\nResult #{i+1}: {profile.get('Full Name', 'Unknown')}\")\n",
    "    print(f\"Document ID: {profile.get('doc_id')}\")  # Display the UUID\n",
    "    print(f\"Position: {profile.get('Current Position', 'N/A')}\")\n",
    "    print(f\"Company: {profile.get('Company', 'N/A')}\")\n",
    "    print(f\"Location: {profile.get('Location', 'N/A')}\")\n",
    "    if profile.get('Skills'):\n",
    "        print(f\"Skills: {profile.get('Skills')}\")\n",
    "    \n",
    "    # Print a snippet of the document content\n",
    "    content = doc.page_content\n",
    "    if len(content) > 200:\n",
    "        print(f\"Content snippet: {content[:200]}...\")\n",
    "    else:\n",
    "        print(f\"Content: {content}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUERY:\n",
    "{question}\n",
    "\n",
    "You are a helpful assistant. Use the available context to answer the question. If you can't answer the question, say you don't know.\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "openai_chat_model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | rag_prompt | openai_chat_model | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided context, here are a few founders who could be a good fit for a startup developing a platform for AI agents to collaborate on tasks:\\n\\n1. **Mark Goldenson**\\n   - **Location:** Mountain View, California, United States\\n   - **Tagline:** Founder & startup investor\\n   - **About:** Mark has extensive experience in startups and technology. His focus includes building products that solve real-world problems and helping founders. His background in product management, especially at Google, could be advantageous for developing collaborative AI systems.\\n\\n   **LinkedIn:** [Mark Goldenson](https://www.linkedin.com/in/goldenson)\\n\\n2. **Alexey Skutin**\\n   - **Location:** Pacifica, California, United States\\n   - **Tagline:** Founder @ Aide AI | Co-Founder and CTO @ CultureBee | IT Expertise\\n   - **About:** Alexey has 20+ years of experience in the IT industry, specializing in enterprise, security, and SaaS/PaaS software. His leadership in creating complex high-load systems and innovative products could facilitate the development of a platform for AI agents.\\n\\n   **LinkedIn:** [Alexey Skutin](https://www.linkedin.com/in/alexey-skutin-ph-d-6b25356)\\n\\nBoth founders have relevant experience in technology, product management, and entrepreneurial leadership, making them strong candidates for your startup's vision.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"question\" : \"can you help me find founders who would be a good fit for a startup that is building a platform for AI agents to collaborate on tasks?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1913.69s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "os.environ[\"RAGAS_APP_TOKEN\"] = getpass(\"Please enter your Ragas API key!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1959.16s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rapidfuzz\n",
      "  Obtaining dependency information for rapidfuzz from https://files.pythonhosted.org/packages/1d/ce/f209f437c6df46ba523a6898ebd854b30196650f77dcddf203191f09bf9b/rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Using cached rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Installing collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.12.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  24%|██▍       | 5/21 [00:24<01:18,  4.93s/it]   Property 'summary' already exists in node '13636c'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/113 [00:00<?, ?it/s]Property 'summary_embedding' already exists in node '13636c'. Skipping!\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  73%|███████▎  | 83/113 [02:46<01:39,  3.33s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-LsdVv2bXqJ9TPrSXuJ0Tazh3 on tokens per min (TPM): Limit 30000, Used 28335, Requested 3502. Please try again in 3.674s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  83%|████████▎ | 94/113 [03:22<01:10,  3.73s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-LsdVv2bXqJ9TPrSXuJ0Tazh3 on tokens per min (TPM): Limit 30000, Used 29409, Requested 4051. Please try again in 6.92s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  90%|█████████ | 102/113 [04:00<01:04,  5.85s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-LsdVv2bXqJ9TPrSXuJ0Tazh3 on tokens per min (TPM): Limit 30000, Used 28024, Requested 4850. Please try again in 5.748s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  96%|█████████▌| 108/113 [04:34<00:32,  6.46s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-LsdVv2bXqJ9TPrSXuJ0Tazh3 on tokens per min (TPM): Limit 30000, Used 29331, Requested 4239. Please try again in 7.14s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Generating personas: 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]                                             \n",
      "Generating Scenarios: 100%|██████████| 3/3 [00:28<00:00,  9.43s/it]\n",
      "Generating Samples: 100%|██████████| 12/12 [01:38<00:00,  8.20s/it]\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(documents, testset_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wht is the role of SignalRank Corporation?</td>\n",
       "      <td>[Experience\",\"Consumer Internet\",\"Digital Mark...</td>\n",
       "      <td>SignalRank Corporation is a company where the ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What JPRS do in Japan?</td>\n",
       "      <td>[about the IP Communications space, and partic...</td>\n",
       "      <td>In Japan, JPRS was involved in deals for names...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What services does Airbnb provide?</td>\n",
       "      <td>[Experience: [{\"Company Name\":\"Start-up-Chris-...</td>\n",
       "      <td>Airbnb, Inc. operates an online marketplace fo...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What role does Airbnb play in Christopher Ober...</td>\n",
       "      <td>[Name: Christopher Obereder Location: Atherton...</td>\n",
       "      <td>Airbnb is one of the industry giants included ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does Poornima Vijayashanker's experience i...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nName: Poornima Vijayashanker Locat...</td>\n",
       "      <td>Poornima Vijayashanker's role at Apple involve...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does B. Pagels-Minor's advocacy for mutual...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nName: B. Pagels-Minor Location: Lo...</td>\n",
       "      <td>B. Pagels-Minor's advocacy for mutual accounta...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How has Mark Goldenson's experience in artific...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nEducation\",\"HR and Recruiting\",\"He...</td>\n",
       "      <td>Mark Goldenson's extensive experience in artif...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How has Greg Badros contributed to brand trans...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nExperience: [{\"Company Name\":\"Glur...</td>\n",
       "      <td>Greg Badros has significantly contributed to b...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does Greg Badros' experience and expertise...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nName: Greg Badros Location: Los Al...</td>\n",
       "      <td>Greg Badros, with his extensive experience in ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How has Jeff Pressman's experience with Operam...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nName: Jeff Pressman Location: Los ...</td>\n",
       "      <td>Jeff Pressman's experience with Operam, where ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How did Oliver Walsh's role at Aritzia contrib...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nExperience: [{\"Company Name\":\"Invi...</td>\n",
       "      <td>Oliver Walsh served as the CMO &amp; Board Directo...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How did Poornima Vijayashanker's experience wi...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nSkills: [\"Software Development\",\"P...</td>\n",
       "      <td>Poornima Vijayashanker's experience with OPEAR...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0          Wht is the role of SignalRank Corporation?   \n",
       "1                              What JPRS do in Japan?   \n",
       "2                  What services does Airbnb provide?   \n",
       "3   What role does Airbnb play in Christopher Ober...   \n",
       "4   How does Poornima Vijayashanker's experience i...   \n",
       "5   How does B. Pagels-Minor's advocacy for mutual...   \n",
       "6   How has Mark Goldenson's experience in artific...   \n",
       "7   How has Greg Badros contributed to brand trans...   \n",
       "8   How does Greg Badros' experience and expertise...   \n",
       "9   How has Jeff Pressman's experience with Operam...   \n",
       "10  How did Oliver Walsh's role at Aritzia contrib...   \n",
       "11  How did Poornima Vijayashanker's experience wi...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [Experience\",\"Consumer Internet\",\"Digital Mark...   \n",
       "1   [about the IP Communications space, and partic...   \n",
       "2   [Experience: [{\"Company Name\":\"Start-up-Chris-...   \n",
       "3   [Name: Christopher Obereder Location: Atherton...   \n",
       "4   [<1-hop>\\n\\nName: Poornima Vijayashanker Locat...   \n",
       "5   [<1-hop>\\n\\nName: B. Pagels-Minor Location: Lo...   \n",
       "6   [<1-hop>\\n\\nEducation\",\"HR and Recruiting\",\"He...   \n",
       "7   [<1-hop>\\n\\nExperience: [{\"Company Name\":\"Glur...   \n",
       "8   [<1-hop>\\n\\nName: Greg Badros Location: Los Al...   \n",
       "9   [<1-hop>\\n\\nName: Jeff Pressman Location: Los ...   \n",
       "10  [<1-hop>\\n\\nExperience: [{\"Company Name\":\"Invi...   \n",
       "11  [<1-hop>\\n\\nSkills: [\"Software Development\",\"P...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   SignalRank Corporation is a company where the ...   \n",
       "1   In Japan, JPRS was involved in deals for names...   \n",
       "2   Airbnb, Inc. operates an online marketplace fo...   \n",
       "3   Airbnb is one of the industry giants included ...   \n",
       "4   Poornima Vijayashanker's role at Apple involve...   \n",
       "5   B. Pagels-Minor's advocacy for mutual accounta...   \n",
       "6   Mark Goldenson's extensive experience in artif...   \n",
       "7   Greg Badros has significantly contributed to b...   \n",
       "8   Greg Badros, with his extensive experience in ...   \n",
       "9   Jeff Pressman's experience with Operam, where ...   \n",
       "10  Oliver Walsh served as the CMO & Board Directo...   \n",
       "11  Poornima Vijayashanker's experience with OPEAR...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset uploaded! View at https://app.ragas.io/dashboard/alignment/testset/463522e1-c768-4c3d-ac15-47caad4f1e26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://app.ragas.io/dashboard/alignment/testset/463522e1-c768-4c3d-ac15-47caad4f1e26'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "  retrieved_docs = retriever.invoke(state[\"question\"])\n",
    "  return {\"context\" : retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\\\n",
    "You are a helpful assistant who answers questions based on provided context. You must only use the provided context, and cannot use your own knowledge.\n",
    "\n",
    "### Question\n",
    "{question}\n",
    "\n",
    "### Context\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "  docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "  messages = rag_prompt.format_messages(question=state[\"question\"], context=docs_content)\n",
    "  response = llm.invoke(messages)\n",
    "  return {\"response\" : response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class State(TypedDict):\n",
    "  question: str\n",
    "  context: List[Document]\n",
    "  response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\"question\" : \"Which profiles are best suited for building autonomous agents startups?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The profiles best suited for building autonomous agents startups based on the provided context include:\\n\\n1. **Christopher Obereder**: \\n   - Position: Chief Executive Officer at Start-Up-Chris Ventures\\n   - Experience: Over 12 years in tech, notable for his background in venture capital, entrepreneurship, and growth hacking. He has successfully led multiple startups and invested heavily in the tech industry, including major players in blockchain and software.\\n   - Skills: Strong in fundraising and growth strategies, making him well-placed to drive startups focusing on innovative solutions like autonomous agents.\\n\\n2. **Anthony Kelani**:\\n   - Position: Chief Technology Officer at Mursion\\n   - Experience: Over 20 years in the tech industry, with a strong focus on artificial intelligence and real-time technology. He is actively developing AI-powered platforms that simulate human interactions, which align closely with the fundamentals of creating autonomous agents.\\n   - Skills: Expertise in artificial intelligence and immersive simulations, crucial for developing and deploying autonomous agents.\\n\\n3. **Alexey Skutin**:\\n   - Position: Founder at AideAI\\n   - Experience: Over 20 years in IT, with a focus on enterprise and security software. His specialization includes creating successful SaaS platforms and managing high-tech projects.\\n   - Skills: Strong technical background combined with entrepreneurial experience, making him a suitable candidate for building solutions around autonomous agents.\\n\\nThese professionals have the necessary experience, skills, and transformational vision aimed at advancing autonomous agent technology and building successful startups in this domain.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_row in dataset:\n",
    "  response = graph.invoke({\"question\" : test_row.eval_sample.user_input})\n",
    "  test_row.eval_sample.response = response[\"response\"]\n",
    "  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wht is the role of SignalRank Corporation?</td>\n",
       "      <td>[Name: Keith Teare\\nLocation: Palo Alto, Calif...</td>\n",
       "      <td>[Experience\",\"Consumer Internet\",\"Digital Mark...</td>\n",
       "      <td>The role of SignalRank Corporation, as describ...</td>\n",
       "      <td>SignalRank Corporation is a company where the ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What JPRS do in Japan?</td>\n",
       "      <td>[Name: coinstats.app\\nLocation: 42629\\nAbout: ...</td>\n",
       "      <td>[about the IP Communications space, and partic...</td>\n",
       "      <td>The context provided does not contain any spec...</td>\n",
       "      <td>In Japan, JPRS was involved in deals for names...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What services does Airbnb provide?</td>\n",
       "      <td>[Name: Allen Narcisse\\nLocation: Los Angeles, ...</td>\n",
       "      <td>[Experience: [{\"Company Name\":\"Start-up-Chris-...</td>\n",
       "      <td>The provided context does not mention Airbnb o...</td>\n",
       "      <td>Airbnb, Inc. operates an online marketplace fo...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What role does Airbnb play in Christopher Ober...</td>\n",
       "      <td>[Name: Christopher Obereder\\nLocation: Atherto...</td>\n",
       "      <td>[Name: Christopher Obereder Location: Atherton...</td>\n",
       "      <td>Airbnb plays a significant role in Christopher...</td>\n",
       "      <td>Airbnb is one of the industry giants included ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does Poornima Vijayashanker's experience i...</td>\n",
       "      <td>[Name: Poornima Vijayashanker\\nLocation: Palo ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nName: Poornima Vijayashanker Locat...</td>\n",
       "      <td>Poornima Vijayashanker's experience in cross-f...</td>\n",
       "      <td>Poornima Vijayashanker's role at Apple involve...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does B. Pagels-Minor's advocacy for mutual...</td>\n",
       "      <td>[Name: B. Pagels-Minor\\nLocation: Los Angeles,...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nName: B. Pagels-Minor Location: Lo...</td>\n",
       "      <td>B. Pagels-Minor's advocacy for mutual accounta...</td>\n",
       "      <td>B. Pagels-Minor's advocacy for mutual accounta...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How has Mark Goldenson's experience in artific...</td>\n",
       "      <td>[Name: Mark Goldenson\\nLocation: Mountain View...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nEducation\",\"HR and Recruiting\",\"He...</td>\n",
       "      <td>Mark Goldenson's extensive experience in artif...</td>\n",
       "      <td>Mark Goldenson's extensive experience in artif...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How has Greg Badros contributed to brand trans...</td>\n",
       "      <td>[Name: Greg Badros\\nLocation: Los Altos, Calif...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nExperience: [{\"Company Name\":\"Glur...</td>\n",
       "      <td>Greg Badros has made significant contributions...</td>\n",
       "      <td>Greg Badros has significantly contributed to b...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does Greg Badros' experience and expertise...</td>\n",
       "      <td>[Name: Greg Badros\\nLocation: Los Altos, Calif...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nName: Greg Badros Location: Los Al...</td>\n",
       "      <td>Greg Badros' experience and expertise signific...</td>\n",
       "      <td>Greg Badros, with his extensive experience in ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How has Jeff Pressman's experience with Operam...</td>\n",
       "      <td>[Name: Jeff Pressman\\nLocation: Los Angeles, C...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nName: Jeff Pressman Location: Los ...</td>\n",
       "      <td>Jeff Pressman's experience with Operam and OPE...</td>\n",
       "      <td>Jeff Pressman's experience with Operam, where ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How did Oliver Walsh's role at Aritzia contrib...</td>\n",
       "      <td>[Name: Oliver Walsh\\nLocation: Los Angeles, Ca...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nExperience: [{\"Company Name\":\"Invi...</td>\n",
       "      <td>Oliver Walsh's role at Aritzia significantly c...</td>\n",
       "      <td>Oliver Walsh served as the CMO &amp; Board Directo...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How did Poornima Vijayashanker's experience wi...</td>\n",
       "      <td>[Name: Poornima Vijayashanker\\nLocation: Palo ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nSkills: [\"Software Development\",\"P...</td>\n",
       "      <td>Poornima Vijayashanker's experience with OPEAR...</td>\n",
       "      <td>Poornima Vijayashanker's experience with OPEAR...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0          Wht is the role of SignalRank Corporation?   \n",
       "1                              What JPRS do in Japan?   \n",
       "2                  What services does Airbnb provide?   \n",
       "3   What role does Airbnb play in Christopher Ober...   \n",
       "4   How does Poornima Vijayashanker's experience i...   \n",
       "5   How does B. Pagels-Minor's advocacy for mutual...   \n",
       "6   How has Mark Goldenson's experience in artific...   \n",
       "7   How has Greg Badros contributed to brand trans...   \n",
       "8   How does Greg Badros' experience and expertise...   \n",
       "9   How has Jeff Pressman's experience with Operam...   \n",
       "10  How did Oliver Walsh's role at Aritzia contrib...   \n",
       "11  How did Poornima Vijayashanker's experience wi...   \n",
       "\n",
       "                                   retrieved_contexts  \\\n",
       "0   [Name: Keith Teare\\nLocation: Palo Alto, Calif...   \n",
       "1   [Name: coinstats.app\\nLocation: 42629\\nAbout: ...   \n",
       "2   [Name: Allen Narcisse\\nLocation: Los Angeles, ...   \n",
       "3   [Name: Christopher Obereder\\nLocation: Atherto...   \n",
       "4   [Name: Poornima Vijayashanker\\nLocation: Palo ...   \n",
       "5   [Name: B. Pagels-Minor\\nLocation: Los Angeles,...   \n",
       "6   [Name: Mark Goldenson\\nLocation: Mountain View...   \n",
       "7   [Name: Greg Badros\\nLocation: Los Altos, Calif...   \n",
       "8   [Name: Greg Badros\\nLocation: Los Altos, Calif...   \n",
       "9   [Name: Jeff Pressman\\nLocation: Los Angeles, C...   \n",
       "10  [Name: Oliver Walsh\\nLocation: Los Angeles, Ca...   \n",
       "11  [Name: Poornima Vijayashanker\\nLocation: Palo ...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [Experience\",\"Consumer Internet\",\"Digital Mark...   \n",
       "1   [about the IP Communications space, and partic...   \n",
       "2   [Experience: [{\"Company Name\":\"Start-up-Chris-...   \n",
       "3   [Name: Christopher Obereder Location: Atherton...   \n",
       "4   [<1-hop>\\n\\nName: Poornima Vijayashanker Locat...   \n",
       "5   [<1-hop>\\n\\nName: B. Pagels-Minor Location: Lo...   \n",
       "6   [<1-hop>\\n\\nEducation\",\"HR and Recruiting\",\"He...   \n",
       "7   [<1-hop>\\n\\nExperience: [{\"Company Name\":\"Glur...   \n",
       "8   [<1-hop>\\n\\nName: Greg Badros Location: Los Al...   \n",
       "9   [<1-hop>\\n\\nName: Jeff Pressman Location: Los ...   \n",
       "10  [<1-hop>\\n\\nExperience: [{\"Company Name\":\"Invi...   \n",
       "11  [<1-hop>\\n\\nSkills: [\"Software Development\",\"P...   \n",
       "\n",
       "                                             response  \\\n",
       "0   The role of SignalRank Corporation, as describ...   \n",
       "1   The context provided does not contain any spec...   \n",
       "2   The provided context does not mention Airbnb o...   \n",
       "3   Airbnb plays a significant role in Christopher...   \n",
       "4   Poornima Vijayashanker's experience in cross-f...   \n",
       "5   B. Pagels-Minor's advocacy for mutual accounta...   \n",
       "6   Mark Goldenson's extensive experience in artif...   \n",
       "7   Greg Badros has made significant contributions...   \n",
       "8   Greg Badros' experience and expertise signific...   \n",
       "9   Jeff Pressman's experience with Operam and OPE...   \n",
       "10  Oliver Walsh's role at Aritzia significantly c...   \n",
       "11  Poornima Vijayashanker's experience with OPEAR...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   SignalRank Corporation is a company where the ...   \n",
       "1   In Japan, JPRS was involved in deals for names...   \n",
       "2   Airbnb, Inc. operates an online marketplace fo...   \n",
       "3   Airbnb is one of the industry giants included ...   \n",
       "4   Poornima Vijayashanker's role at Apple involve...   \n",
       "5   B. Pagels-Minor's advocacy for mutual accounta...   \n",
       "6   Mark Goldenson's extensive experience in artif...   \n",
       "7   Greg Badros has significantly contributed to b...   \n",
       "8   Greg Badros, with his extensive experience in ...   \n",
       "9   Jeff Pressman's experience with Operam, where ...   \n",
       "10  Oliver Walsh served as the CMO & Board Directo...   \n",
       "11  Poornima Vijayashanker's experience with OPEAR...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   multi_hop_abstract_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  \n",
       "11  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  24%|██▎       | 17/72 [05:21<26:20, 28.74s/it]Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Evaluating:  25%|██▌       | 18/72 [06:00<28:38, 31.82s/it]Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[16]: TimeoutError()\n",
      "Evaluating:  32%|███▏      | 23/72 [06:02<08:34, 10.51s/it]Exception raised in Job[18]: TimeoutError()\n",
      "Evaluating:  33%|███▎      | 24/72 [06:03<07:07,  8.91s/it]Exception raised in Job[19]: TimeoutError()\n",
      "Evaluating:  38%|███▊      | 27/72 [06:11<04:30,  6.00s/it]Exception raised in Job[22]: TimeoutError()\n",
      "Evaluating:  40%|████      | 29/72 [06:41<06:42,  9.36s/it]Exception raised in Job[23]: TimeoutError()\n",
      "Evaluating:  42%|████▏     | 30/72 [06:47<05:56,  8.50s/it]Exception raised in Job[24]: TimeoutError()\n",
      "Evaluating:  44%|████▍     | 32/72 [06:57<04:43,  7.09s/it]Exception raised in Job[25]: TimeoutError()\n",
      "Evaluating:  53%|█████▎    | 38/72 [10:07<15:53, 28.04s/it]Exception raised in Job[30]: TimeoutError()\n",
      "Evaluating:  56%|█████▌    | 40/72 [10:35<11:00, 20.65s/it]Exception raised in Job[31]: TimeoutError()\n",
      "Evaluating:  60%|█████▉    | 43/72 [11:49<10:34, 21.87s/it]Exception raised in Job[34]: TimeoutError()\n",
      "Exception raised in Job[35]: TimeoutError()\n",
      "Exception raised in Job[36]: TimeoutError()\n",
      "Evaluating:  61%|██████    | 44/72 [12:00<08:40, 18.59s/it]Exception raised in Job[37]: TimeoutError()\n",
      "Exception raised in Job[40]: TimeoutError()\n",
      "Evaluating:  68%|██████▊   | 49/72 [12:08<02:41,  7.00s/it]Exception raised in Job[41]: TimeoutError()\n",
      "Evaluating:  69%|██████▉   | 50/72 [12:10<02:10,  5.92s/it]Exception raised in Job[42]: TimeoutError()\n",
      "Evaluating:  72%|███████▏  | 52/72 [12:17<01:42,  5.13s/it]Exception raised in Job[43]: TimeoutError()\n",
      "Evaluating:  74%|███████▎  | 53/72 [12:30<02:14,  7.08s/it]Exception raised in Job[46]: TimeoutError()\n",
      "Evaluating:  76%|███████▋  | 55/72 [12:53<02:26,  8.60s/it]Exception raised in Job[47]: TimeoutError()\n",
      "Evaluating:  78%|███████▊  | 56/72 [12:57<01:56,  7.28s/it]Exception raised in Job[48]: TimeoutError()\n",
      "Evaluating:  81%|████████  | 58/72 [13:27<02:48, 12.05s/it]Exception raised in Job[49]: TimeoutError()\n",
      "Evaluating:  85%|████████▍ | 61/72 [15:28<06:36, 36.03s/it]Exception raised in Job[52]: TimeoutError()\n",
      "Evaluating:  86%|████████▌ | 62/72 [15:43<04:59, 29.94s/it]Exception raised in Job[53]: TimeoutError()\n",
      "Evaluating:  92%|█████████▏| 66/72 [17:59<03:15, 32.55s/it]Exception raised in Job[60]: TimeoutError()\n",
      "Evaluating:  93%|█████████▎| 67/72 [18:00<01:54, 22.92s/it]Exception raised in Job[64]: TimeoutError()\n",
      "Evaluating:  94%|█████████▍| 68/72 [18:08<01:14, 18.66s/it]Exception raised in Job[66]: TimeoutError()\n",
      "Evaluating:  96%|█████████▌| 69/72 [18:11<00:41, 13.83s/it]Exception raised in Job[67]: TimeoutError()\n",
      "Evaluating:  97%|█████████▋| 70/72 [18:17<00:23, 11.59s/it]Exception raised in Job[70]: TimeoutError()\n",
      "Evaluating:  99%|█████████▊| 71/72 [18:53<00:19, 19.01s/it]Exception raised in Job[71]: TimeoutError()\n",
      "Evaluating: 100%|██████████| 72/72 [18:57<00:00, 15.80s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.3333, 'faithfulness': 0.5122, 'factual_correctness': 0.4292, 'answer_relevancy': 0.7233, 'context_entity_recall': 0.4103, 'noise_sensitivity_relevant': 0.1962}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
    "from ragas import evaluate, RunConfig\n",
    "\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=custom_run_config\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of RAGAS Eval Prior to Fine-tuning:\n",
    "{'context_recall': 0.3333, 'faithfulness': 0.5122, 'factual_correctness': 0.4292, 'answer_relevancy': 0.7233, 'context_entity_recall': 0.4103, 'noise_sensitivity_relevant': 0.1962}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 750,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len\n",
    ")\n",
    "training_documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_set = set()\n",
    "\n",
    "for document in training_documents:\n",
    "  id = str(uuid.uuid4())\n",
    "  while id in id_set:\n",
    "    id = uuid.uuid4()\n",
    "  id_set.add(id)\n",
    "  document.metadata[\"id\"] = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 393\n",
      "Validation set size: 60\n",
      "Test set size: 60\n",
      "Total: 513\n"
     ]
    }
   ],
   "source": [
    "# For a dataset of 513 documents\n",
    "# Maintaining approximately the same proportions (76.5% / 11.8% / 11.8%)\n",
    "\n",
    "# Calculate the number of documents for validation and test sets\n",
    "val_size = int(513 * 0.118)  # ~60 documents\n",
    "test_size = int(513 * 0.118)  # ~60 documents\n",
    "train_size = 513 - val_size - test_size  # ~393 documents\n",
    "\n",
    "# Create the splits\n",
    "training_split_documents = training_documents[:train_size]\n",
    "val_split_documents = training_documents[train_size:train_size + val_size]\n",
    "test_split_documents = training_documents[train_size + val_size:]\n",
    "\n",
    "# Print the sizes to verify\n",
    "print(f\"Training set size: {len(training_split_documents)}\")\n",
    "print(f\"Validation set size: {len(val_split_documents)}\")\n",
    "print(f\"Test set size: {len(test_split_documents)}\")\n",
    "print(f\"Total: {len(training_split_documents) + len(val_split_documents) + len(test_split_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "qa_chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "qa_prompt = \"\"\"\\\n",
    "Given the following context, you must generate questions based on only the provided context.\n",
    "\n",
    "You are to generate {n_questions} questions which should be provided in the following format:\n",
    "\n",
    "1. QUESTION #1\n",
    "2. QUESTION #2\n",
    "...\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "qa_prompt_template = ChatPromptTemplate.from_template(qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generation_chain = qa_prompt_template | qa_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "\n",
    "async def process_document(document, n_questions):\n",
    "    questions_generated = await question_generation_chain.ainvoke({\"context\": document.page_content, \"n_questions\": n_questions})\n",
    "    \n",
    "    doc_questions = {}\n",
    "    doc_relevant_docs = {}\n",
    "    \n",
    "    for question in questions_generated.content.split(\"\\n\"):\n",
    "        question_id = str(uuid.uuid4())\n",
    "        doc_questions[question_id] = \"\".join(question.split(\".\")[1:]).strip()\n",
    "        doc_relevant_docs[question_id] = [document.metadata[\"id\"]]\n",
    "    \n",
    "    return doc_questions, doc_relevant_docs\n",
    "\n",
    "async def create_questions(documents, n_questions):\n",
    "    tasks = [process_document(doc, n_questions) for doc in documents]\n",
    "    \n",
    "    questions = {}\n",
    "    relevant_docs = {}\n",
    "    \n",
    "    for task in tqdm(asyncio.as_completed(tasks), total=len(documents), desc=\"Processing documents\"):\n",
    "        doc_questions, doc_relevant_docs = await task\n",
    "        questions.update(doc_questions)\n",
    "        relevant_docs.update(doc_relevant_docs)\n",
    "    return questions, relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 393/393 [00:13<00:00, 29.88it/s] \n"
     ]
    }
   ],
   "source": [
    "training_questions, training_relevant_contexts = await create_questions(training_split_documents, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 60/60 [00:06<00:00,  9.04it/s]\n"
     ]
    }
   ],
   "source": [
    "val_questions, val_relevant_contexts = await create_questions(val_split_documents, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 60/60 [00:03<00:00, 17.98it/s]\n"
     ]
    }
   ],
   "source": [
    "test_questions, test_relevant_contexts = await create_questions(test_split_documents, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "training_corpus = {train_item.metadata[\"id\"] : train_item.page_content for train_item in training_split_documents}\n",
    "\n",
    "train_dataset = {\n",
    "    \"questions\" : training_questions,\n",
    "    \"relevant_contexts\" : training_relevant_contexts,\n",
    "    \"corpus\" : training_corpus\n",
    "}\n",
    "\n",
    "with open(\"training_dataset.jsonl\", \"w\") as f:\n",
    "  json.dump(train_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_corpus = {val_item.metadata[\"id\"] : val_item.page_content for val_item in val_split_documents}\n",
    "\n",
    "val_dataset = {\n",
    "    \"questions\" : val_questions,\n",
    "    \"relevant_contexts\" : val_relevant_contexts,\n",
    "    \"corpus\" : val_corpus\n",
    "}\n",
    "\n",
    "with open(\"val_dataset.jsonl\", \"w\") as f:\n",
    "  json.dump(val_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = {test_item.metadata[\"id\"] : test_item.page_content for test_item in test_split_documents}\n",
    "\n",
    "test_dataset = {\n",
    "    \"questions\" : test_questions,\n",
    "    \"relevant_contexts\" : test_relevant_contexts,\n",
    "    \"corpus\" : train_corpus\n",
    "}\n",
    "\n",
    "with open(\"test_dataset.jsonl\", \"w\") as f:\n",
    "  json.dump(test_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6998.55s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU sentence_transformers datasets pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_id = \"Snowflake/snowflake-arctic-embed-l\"\n",
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from sentence_transformers import InputExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train_dataset['corpus']\n",
    "queries = train_dataset['questions']\n",
    "relevant_docs = train_dataset['relevant_contexts']\n",
    "\n",
    "examples = []\n",
    "for query_id, query in queries.items():\n",
    "    doc_id = relevant_docs[query_id][0]\n",
    "    text = corpus[doc_id]\n",
    "    example = InputExample(texts=[query, text])\n",
    "    examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    examples, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
    "\n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64]\n",
    "inner_train_loss = MultipleNegativesRankingLoss(model)\n",
    "train_loss = MatryoshkaLoss(\n",
    "    model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "\n",
    "corpus = val_dataset['corpus']\n",
    "queries = val_dataset['questions']\n",
    "relevant_docs = val_dataset['relevant_contexts']\n",
    "\n",
    "evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7323.92s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Obtaining dependency information for wandb from https://files.pythonhosted.org/packages/7d/53/361846bf44dcf3bc5a4be0e0cb662b42c7e6996d71c903c936e191657e0d/wandb-0.19.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading wandb-0.19.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in ./.venv/lib/python3.11/site-packages (from wandb) (8.1.8)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Obtaining dependency information for docker-pycreds>=0.4.0 from https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Obtaining dependency information for gitpython!=3.1.29,>=1.0.0 from https://files.pythonhosted.org/packages/1d/9a/4114a9057db2f1462d5c8f8390ab7383925fe1ac012eaa42402ad65c2963/GitPython-3.1.44-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in ./.venv/lib/python3.11/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in ./.venv/lib/python3.11/site-packages (from wandb) (5.29.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./.venv/lib/python3.11/site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in ./.venv/lib/python3.11/site-packages (from wandb) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.11/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Obtaining dependency information for sentry-sdk>=2.0.0 from https://files.pythonhosted.org/packages/12/7f/0e4459173e9671ba5f75a48dda2442bcc48a12c79e54e5789381c8c6a9bc/sentry_sdk-2.22.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading sentry_sdk-2.22.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Obtaining dependency information for setproctitle from https://files.pythonhosted.org/packages/31/6e/baaf70bd9a881dd8c12cbccdd7ca0ff291024a37044a8245e942e12e7135/setproctitle-1.3.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading setproctitle-1.3.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from wandb) (65.5.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in ./.venv/lib/python3.11/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in ./.venv/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/a0/61/5c78b91c3143ed5c14207f463aecfc8f9dbb5092fb2869baf37c273b2705/gitdb-4.0.12-py3-none-any.whl.metadata\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/04/be/d09147ad1ec7934636ad912901c5fd7667e1c858e19d355237db0d0cd5e4/smmap-5.0.2-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.19.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.22.0-py2.py3-none-any.whl (325 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.8/325.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.12 gitpython-3.1.44 sentry-sdk-2.22.0 setproctitle-1.3.5 smmap-5.0.2 wandb-0.19.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/o50svu13?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa06d3caad0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7863.63s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU faiss-cpu python-pptx==1.0.2 nltk==3.9.1 pymupdf beautifulsoup4 lxml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7805.20s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8136.05s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.11/site-packages (3.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (0.29.1)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235141.37s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU transformers[torch]>=4.48.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235202.65s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU accelerate>=1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m warmup_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(loader) \u001b[38;5;241m*\u001b[39m EPOCHS \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinetuned_arctic_ft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/aie5/code/aie5/Midterm/.venv/lib/python3.11/site-packages/sentence_transformers/fit_mixin.py:318\u001b[0m, in \u001b[0;36mFitMixin.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# Transformers renamed `evaluation_strategy` to `eval_strategy` in v4.41.0\u001b[39;00m\n\u001b[1;32m    313\u001b[0m eval_strategy_key \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(transformers\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.41.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    317\u001b[0m )\n\u001b[0;32m--> 318\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformerTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_default_checkpoint_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_dataset_batch_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMultiDatasetBatchSamplers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mROUND_ROBIN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_strategy_key\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevaluation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevaluation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# load_best_model_at_end=save_best_model, # <- TODO: Look into a good solution for save_best_model\u001b[39;49;00m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_amp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_save_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_save_total_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m steps_per_epoch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m steps_per_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    340\u001b[0m     steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m([\u001b[38;5;28mlen\u001b[39m(train_dataset) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size \u001b[38;5;28;01mfor\u001b[39;00m train_dataset \u001b[38;5;129;01min\u001b[39;00m train_dataset_dict\u001b[38;5;241m.\u001b[39mvalues()])\n",
      "File \u001b[0;32m<string>:137\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices, prompts, batch_sampler, multi_dataset_batch_sampler)\u001b[0m\n",
      "File \u001b[0;32m~/aie5/code/aie5/Midterm/.venv/lib/python3.11/site-packages/sentence_transformers/training_args.py:190\u001b[0m, in \u001b[0;36mSentenceTransformerTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__post_init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__post_init__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_sampler \u001b[38;5;241m=\u001b[39m BatchSamplers(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_sampler)\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_dataset_batch_sampler \u001b[38;5;241m=\u001b[39m MultiDatasetBatchSamplers(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_dataset_batch_sampler)\n",
      "File \u001b[0;32m~/aie5/code/aie5/Midterm/.venv/lib/python3.11/site-packages/transformers/training_args.py:1791\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[0;32m-> 1791\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_tokens_across_devices:\n",
      "File \u001b[0;32m~/aie5/code/aie5/Midterm/.venv/lib/python3.11/site-packages/transformers/training_args.py:2313\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2309\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2310\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[1;32m   2311\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2312\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[0;32m~/aie5/code/aie5/Midterm/.venv/lib/python3.11/site-packages/transformers/utils/generic.py:62\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     60\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[0;32m~/aie5/code/aie5/Midterm/.venv/lib/python3.11/site-packages/transformers/training_args.py:2186\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m-> 2186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   2187\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2188\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2189\u001b[0m         )\n\u001b[1;32m   2190\u001b[0m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[1;32m   2191\u001b[0m accelerator_state_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menabled\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_configured_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
      "\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`"
     ]
    }
   ],
   "source": [
    "warmup_steps = int(len(loader) * EPOCHS * 0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(loader, train_loss)],\n",
    "    epochs=EPOCHS,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='finetuned_arctic_ft',\n",
    "    show_progress_bar=True,\n",
    "    evaluator=evaluator,\n",
    "    evaluation_steps=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235341.52s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.49.0\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /home/ngiometti/aie5/code/aie5/Midterm/.venv/lib/python3.11/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: sentence-transformers\n",
      "---\n",
      "Name: accelerate\n",
      "Version: 1.4.0\n",
      "Summary: Accelerate\n",
      "Home-page: https://github.com/huggingface/accelerate\n",
      "Author: The HuggingFace team\n",
      "Author-email: zach.mueller@huggingface.co\n",
      "License: Apache\n",
      "Location: /home/ngiometti/aie5/code/aie5/Midterm/.venv/lib/python3.11/site-packages\n",
      "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235483.77s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.6.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: /home/ngiometti/aie5/code/aie5/Midterm/.venv/lib/python3.11/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-cusparselt-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
      "Required-by: accelerate, sentence-transformers\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
